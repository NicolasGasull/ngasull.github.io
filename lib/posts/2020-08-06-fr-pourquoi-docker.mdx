---
title:  "Pourquoi Docker ?"
categories: devops
---

## Pour travailler ensemble
Tout le monde d√©veloppe sur diff√©rentes machines. Il n'est pas rare que plusieurs coll√®gues aient install√© diff√©rentes version d'une m√™me library, d'un package manager, du runtime de leur application... (cc node/npm üëã)

Lorsque l'application de d√©veloppement est dockeris√©e, tous les devs (et la prod !) sont soumis aux m√™mes r√®gles, ce qui √©vite le syndr√¥me de _"mais √ßa marche sur mon PC"_ tout en r√©duisant la configuration n√©cessaire √† installer l'environnement de dev. Voir juste apr√®s !

## Pour moins perdre de temps √† configurer
La configuration, c'est du temps pass√© √† ne pas √™tre productif. Plus il y a d'environnements dans lesquels une application doit tourner, plus il y a de configuration √† faire. Docker permet d'abstraire l'environnement dans lequel tourne l'application et donc de ne faire que le minimum n√©cessaire.

Une cons√©quence notable : pour ajouter un service √† la stack, plus forc√©ment besoin d'apprendre en d√©tails une technologie. Il suffit d'ajouter une image existante de celle-ci, et de simplement sp√©cifier les variables d'environnement n√©cessaires. Par exemple, pour [ajouter une database PostgreSQL](https://hub.docker.com/_/postgres/), il suffit au minimum de renseigner un root password et de monter un volume pour persister les donn√©es.

## Pour s√©parer les probl√®mes
Comme chaque service est aussi simple que possible, chacun n'a que tr√®s peu de d√©pendances avec le reste du monde. On voit que, par nature, les conteneurs nous poussent √† n'avoir que le minimum vital de d√©pendances entre services.

Par d√©pendances, je pense en particulier √† :
- Syst√®me, programmes, libraries install√©es
- Configurations associ√©es √† ce setup
- Volumes (fichiers)
- Acc√®s r√©seau

## Pour g√©rer et s√©curiser les connexions r√©seau
Car oui : c'est vite fait de faire fuiter le port d'une database, et [quand elle n'est pas s√©curis√©e c'est g√™nant](https://www.bleepingcomputer.com/news/security/new-meow-attack-has-deleted-almost-4-000-unsecured-databases/) üò¨

L'id√©e est de penser un service comme une bo√Æte noire qui expose un ou plusieurs ports. Les services communiquent entre eux gr√¢ce aux volumes mont√©s en commun ou √† travers des ports internes. En effet, les [services appartenant √† un m√™me r√©seau](https://docs.docker.com/compose/networking/) peuvent par d√©faut s'acc√©der entre eux.


## Pi√®ges et trucs √† savoir
Sous Windows et Mac, les conteneurs tournent sur une VM. Du coup c'est lent, pas natif et les lectures/√©critures disque peuvent ralentir l'√©dition de fichiers. La solution est simple : utilise Linux üòè (ou un Windows/Mac puissant)

Lorsqu'un m√™me volume (dossier) est mont√© en √©criture dans deux conteneurs √† la fois, on peut se retrouver avec des comportements inattendus : chez moi, l'int√©gralit√© du dossier g√©n√©r√© par un run de build disparaissait en m√™me temps que le conteneur √† la fin du run. Je recommande donc vivement de ne monter en √©criture qu'un seul fichier ou dossier √† la fois.

C'est possible de ne partager en √©criture qu'une partie d'une m√™me arborescence commune. Par exemple, si `backend` et `frontend` partagent `code` en lecture mais que `backend` doit √©crire dans `code/target` et `frontend` doit √©crire dans `code/dist`, alors les volumes peuvent √™tre surcharg√©s comme ceci :
```yml
backend:
  volumes:
    - ./code:/code:ro
    - ./code/target:/code/target

webapp:
  volumes:
    - ./code:/code:ro
    - ./code/dist:/code/dist
```

Les images Docker peuvent vite prendre de l'espace disque. Mais avec le temps, la communaut√© opte de plus en plus pour des versions minimalistes de chaque image. Autrefois avec une version _slim_ de Debian, et aujourd'hui souvent avec une version [Alpine Linux](https://alpinelinux.org/about/) qui permet aux images de faire moins de 10Mo de base ! Pr√©f√®re-donc utiliser les tags `-alpine` de chaque image.

Enfin, la gestion des permissions est d√©routante au d√©but. Docker tourne en root par d√©faut et a de bonnes raisons de le faire : autant dire que j'appr√©cie de pouvoir ouvrir les ports 80 ou 443 en dev comme en prod üôÇ

Pour mieux comprendre pourquoi et comment bien g√©rer ses permissions : [voir cet article](/fr/blog/gerer-ses-permissions-avec-docker).


## Par o√π commencer?

En prenant le temps de lire la doc dans l'ordre, tout ne peut que bien se passer :

1. [Comprends Docker](https://docs.docker.com/get-started/overview/)
2. [Comprends docker-compose](https://docs.docker.com/compose/) pour simplement faire cohabiter les services entre eux
3. Installe [docker](https://docs.docker.com/engine/install/) et [docker-compose](https://docs.docker.com/compose/install/)
4. [Ajoute ton user au groupe `docker`](https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user) pour piloter le daemon sans `sudo`
5. C'est parti ! N'oublie pas de garder la configuration la plus simple possible.

<details open={false}>
<summary>Exemple</summary>

Une stack compl√®te React/Rust/PostgreSQL pourrait √™tre lanc√©e avec la simple config suivante √† la racine d'un projet :
```yml
version: "3"
services:
  db:
    image: postgres:alpine
    environment:
      - POSTGRES_PASSWORD=yolo
    volumes:
      - ./db/data:/var/lib/postgresql/data
  backend:
    image: rust:slim
    environment:
      - PGHOST=db
      - PGDATABASE=monservice
      - PGUSER=root
      - PGPASSWORD=yolo
    volumes:
      - ./backend/:/home/backend
      - ./webapp/:/home/webapp:ro
    command: cargo run
    ports:
      - 4000:4000
  webapp:
    image: node:alpine
    environment:
      - YARN_VERSION=1.22
      - BACKEND_URL=http://backend:4000/
    volumes:
      - ./webapp/:/home/webapp
    command: sh -c "yarn install && CI=true yarn start"
    ports:
      - 80:8080
```

`docker-compose up -d` et c'est parti directement sur [localhost](http://localhost) ! üíª
</details>

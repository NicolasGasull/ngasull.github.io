{"pageProps":{"locale":null,"scope":{"date":"2020-02-08","slug":"making-music-programmable-again","lang":"en","title":"Making music programmable again","html":"<section id=\"preamble\" aria-label=\"Preamble\"><p>For adepts of retro-gaming who have some foundation in music, retro-gaming music is a nice area to dig into: it has restrictive musicality, which enables to focus on composition and strong auditive identity.\nBut after weeks or even months of research, I came to realize how sub-developed music synthesis could be in interactive systems like video games.</p>\n<p>This article gives some context about how music used to be made in video games,\nhow game music composition evolved over the years,\nand eventually opens some doors to new creative horizons.</p></section><nav id=\"toc\" class=\"toc\" role=\"doc-toc\"><h2 id=\"toc-title\">Summary</h2><ol class=\"toc-list level-1\"><li><a href=\"#_game_music_in_the_90s\">Game music in the 90‚Äôs</a></li><li><a href=\"#_modern_music_composition\">Modern music composition</a><ol class=\"toc-list level-2\"><li><a href=\"#_synthesis_from_midi\">Synthesis from MIDI</a></li></ol></li><li><a href=\"#_dynamic_music_synthesis_in_2020\">Dynamic music synthesis in 2020?</a></li></ol></nav>\n<section class=\"doc-section level-1\"><h2 id=\"_game_music_in_the_90s\">Game music in the 90‚Äôs</h2><p>Retro games used to synthesize sound on-the-go by the device‚Äôs sound chip or card. This is why retro game music is often referred as <strong>chiptune</strong>.\nMany artists <a href=\"http://battleofthebits.org/\">still compose chiptune nowadays</a> - maybe because nostalgia, or maybe because chiptune focuses on composition rather than picking and tweaking instruments, effects and mastering.\nAnyhow, it‚Äôs an amazing discipline for the hobbyist composer!</p>\n<figure class=\"audio-block\"><audio src=\"/res/audio/flamerepellent-sunvox.ogg\" controls=\"\">Your browser does not support the audio tag.</audio>\n<figcaption>Quick copycat I made based off <a href=\"https://fearofdark.bandcamp.com/album/the-coffee-zone\">Fearofdark‚Äôs amazing work ‚ù§Ô∏è</a></figcaption></figure>\n<p>Chiptune is often composed with a <em>tracker</em>.\nIn a tracker, audio channels are explicitly separated across vertical <strong>tracks</strong>, notes are textually sequenced and can each have its own <strong>instrument</strong> and receive a variety of effects.\nTrackers are here to allow composition while enforcing control over audio channels.</p>\n<figure class=\"image-block\"><img src=\"/img/FastTracker2.png\" alt=\"FastTracker2 screenshot\">\n<figcaption>FastTracker 2, a DOS music tracker</figcaption></figure>\n<p>Although many claim the benefits of the tracker layout because of its compactness, I still think it‚Äôs rather outdated and prevents picturing the music well. The main alternative layout, the <strong>piano roll</strong>, comes closer to music sheets which are the standard of music composition. Notes can intuitively be spanned across time, and music layers can be \"drawn\".</p>\n<figure class=\"image-block\"><img src=\"/img/LMMS_PianoRoll.png\" alt=\"LMMS screenshot\">\n<figcaption>Piano roll in LMMS</figcaption></figure>\n<p>Piano rolls are an essential component of many modern <a href=\"https://en.wikipedia.org/wiki/Digital_audio_workstation\">Digital Audio Workstations (DAW)</a>. Although more visual than trackers, different piano rolls might have many varying features between each other, whereas all trackers are mostly the same.\nThis has an impact on <strong>how little standard piano roll based DAWs</strong> are.</p>\n<p>Most trackers produce <a href=\"https://en.wikipedia.org/wiki/Module_file\"><strong>module files</strong></a>. These files basically separate the <strong>instruments</strong> from the <strong>notes</strong> and <strong>effects</strong>.\nA consequence from separating the instruments' sound data is that the module file is usually <strong>much smaller</strong> than raw audio data.\nMoreover, isolating instruments formalizes the identity of the music‚Äôs sounds. It‚Äôs a bit like picking an orchestra!</p>\n<p>While I love the <em>module</em> format, there are still issues:</p>\n<div class=\"ulist\"><ul><li>Each module file contains its own orchestra</li><li>There are many module formats</li><li>No module format is close to being standard</li></ul></div>\n<p>Because of these, I don‚Äôt see any significant advantage in using module files in video games. Instead, there must be some sort of standard in order to separate instruments from music‚Ä¶‚Äã</p></section>\n<section class=\"doc-section level-1\"><h2 id=\"_modern_music_composition\">Modern music composition</h2><p>Modern video game music seems to have converged with regular \"song\" music along with the evolution of DAWs.\nMost games embed compressed raw audio data and it makes sense for most game dev studios that have a dedicated musicians.</p>\n<p>Producing raw audio gives maximum flexibility in creation: the musician can use and endless variety of instruments, effects, filters, mixes‚Ä¶‚Äã On top of that, raw audio is very easy to play in the game itself and is, of course, standard.</p>\n<p>However, for the indie game developer who wants super-dynamic music progressions, for the hobbyist who doesn‚Äôt master music that well, or for the studio who wants to enforce strong auditive identity in a game as lean as possible: they have reasons to be frustrated.</p>\n<p>Indeed, in a developer‚Äôs mind: why not <strong>making music programmatic</strong>? Graphics can easily be, so why not music?</p>\n<p>There is a standard for having instruments communicate together and with computers: <a href=\"https://en.wikipedia.org/wiki/MIDI\"><strong>MIDI</strong></a>. Instead of transferring raw audio, the MIDI protocol consists in transferring <strong>simpler abstract signals</strong> that will be interpretated according to the receiver. For instance, a MIDI signal can consist of a note with a certain velocity, and the next signal most probably is the release of this note (note off). In this scenario, the same MIDI signals can trigger a very loud note with an echo, a quiet sharp note or even be interpretated as VJ lighting changes!</p>\n<p>MIDI is the standard abstraction layer for digital music. Signals can be realtime or can be stored in a <em>.mid</em> file (called <em>Standard MIDI File</em> or <strong>SMF</strong>). This gives us strong hopes for programmatic music! Provided a sound synthesis library, lightweight signals can become music.</p>\n<section class=\"doc-section level-2\"><h3 id=\"_synthesis_from_midi\">Synthesis from MIDI</h3><p>MIDI now looks like an obvious choice for standard programmatic music.\nHowever I had a hard time finding how to actually play it back from a game.\nMost music learning resources and artists point to proprietary solutions, formats, which work for raw audio but removes programmatic freedom.</p>\n<figure class=\"image-block\"><img src=\"/img/Polyphone.png\" alt=\"Polyphone screenshot\">\n<figcaption>The Polyphone SoundFont editor</figcaption></figure>\n<p>The best solutions I found so far rely on <a href=\"https://en.wikipedia.org/wiki/SoundFont\"><strong>SoundFonts</strong></a>. Despite being non-standard, they are a well-accepted format to define a <strong>bank of instruments</strong>.\nThere are some great pieces of software that make great use of SoundFonts for our purpose, notably:</p>\n<div class=\"ulist\"><ul><li><a href=\"https://github.com/freeors/SDL/blob/master/SDL2_mixer-2.0.1/timidity/timidity.c\">TiMidity</a>, a basic midi player originally written for SDL back in the days (1995). It evolved into its separate repositories and can be used as a library, but is very limited</li><li><a href=\"https://github.com/FluidSynth/fluidsynth\">FluidSynth</a>, a MIDI synthesis library specifically made to work with SoundFonts and play the music itself. FluidSynth is also easily embeddable in DAWs though a <a href=\"https://en.wikipedia.org/wiki/Virtual_Studio_Technology\">VST</a></li></ul></div>\n<p>These libraries are amazing tracks to get started! But I‚Äôm still astonished by the small enthusiasm they grab.\nA consequence of this is how hard it is to leverage the whole capabilities of FluidSynth in a DAW: most DAWs have their own way to manage effects and thus don‚Äôt allow to export those as standard MIDI.\nMoreover, even if <strong>MIDI+Soundfont</strong> looks like a \"standard\" combo, I don‚Äôt know any good DAW that allows both MIDI composing and SoundFont creation/edition at the same time.</p></section></section>\n<section class=\"doc-section level-1\"><h2 id=\"_dynamic_music_synthesis_in_2020\">Dynamic music synthesis in 2020?</h2><p>Now we reach the point of many wonders. It seems like great music technologies from the 90‚Äôs still exist but haven‚Äôt reached their full potential.\nThis didn‚Äôt prevent music itself to evolve, but what about the way music is used interactively?\nThere are countless video games out there, and aside massive franchises, very few are known for their music.\nWorse than that: there are so few music games or games that integrate music as part of the gameplay.</p>\n<p>Despite incredible technology evolutions, I feel like a whole dimension is missing from game development nowadays.\nFor hobbyists, music creativity should be as accessible as visual arts.\nMusic-rich games should be able to fit on a cartridge or a floppy disk like back in the days and should have a well-defined auditive identity.</p>\n<p>If this article resonates with you too, feel free to share, <a href=\"https://twitter.com/ngasull/status/1228238628729409536\">tweet</a> or <a href=\"/about#contact-me\">reach out to me</a> and I‚Äôll be happy to know what you think and what we can do üôÇ I really believe that the creative community deserves better!</p></section>","categories":["music","gamedev"]}},"__N_SSG":true}